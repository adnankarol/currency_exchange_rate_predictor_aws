{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4acFoxTkWPn"
   },
   "source": [
    "# Script for Model Training for Currency Exchange Rate Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBjvHUUYknb4"
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1sz437AVAlg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout,Dense,RepeatVector,TimeDistributed,Input,BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam as adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaEShxFAkqur"
   },
   "source": [
    "## Fetch Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "aQ0-_PKSHPYh",
    "outputId": "008406ac-2b5d-451f-91f4-0cd64898f165"
   },
   "outputs": [],
   "source": [
    "# Prepare dataframe\n",
    "data = pd.read_csv(\"data_resampled_hour.csv\")\n",
    "data = data.rename({\"Unnamed: 0\":\"time\"},axis=1)\n",
    "data = data.set_index(\"time\")\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6XPAMwUkvzW"
   },
   "source": [
    "### Perform Processing to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVYWF8umkzO2"
   },
   "outputs": [],
   "source": [
    "# Look into Last 48 hours and predict next 1 hour \n",
    "n_past= window = 48\n",
    "n_future = 1\n",
    "\n",
    "n_features = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dwk6fwL4Uy9p"
   },
   "outputs": [],
   "source": [
    "# Scaling the Data\n",
    "from sklearn import preprocessing\n",
    "import joblib\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-XuwrCflIxk"
   },
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9JFSAfGJyax",
    "outputId": "c356d885-eca4-477d-c677-5235e54ea306"
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data, test_size=0.1, shuffle=False)\n",
    "\n",
    "train_df,val_df = train_test_split(train_df, test_size=0.35, shuffle=False)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDCmBNJClNPu"
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9M1GdjuKJ7L"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "method: split_series\n",
    "input_parameters: series, n_past, n_future\n",
    "output_parameters: np.array(X), np.array(y)\n",
    "description: This method takes the data and splits it for supervised learning where input is the\n",
    "             last n observations and output is the future m observations. \n",
    "'''\n",
    "\n",
    "\n",
    "def split_series(series, n_past, n_future):\n",
    "    #\n",
    "    # n_past ==> no of past observations\n",
    "    #\n",
    "    # n_future ==> no of future observations\n",
    "    #\n",
    "    X, y = list(), list()\n",
    "    for window_start in range(len(series)):\n",
    "        past_end = window_start + n_past\n",
    "        future_end = past_end + n_future\n",
    "        if future_end > len(series):\n",
    "            break\n",
    "        # slicing the past and future parts of the window\n",
    "        past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
    "        X.append(past)\n",
    "        y.append(future)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKtpfM8oLiPJ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "method: plot_training\n",
    "input_parameters: history\n",
    "output_parameters: none\n",
    "description: This method plots the training and validation performance over the epochs.\n",
    "'''\n",
    "\n",
    "\n",
    "def plot_training(history):\n",
    "    print(history.history.keys())\n",
    "\n",
    "    #  \"MAE: Mean Absolute Error\"\n",
    "    plt.plot(history.history['mae'])\n",
    "    plt.plot(history.history['val_mae'])\n",
    "    plt.title('model mae')\n",
    "    plt.ylabel('mae')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # \"Loss\"\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lirF_8ciKQ9X",
    "outputId": "be12a61c-97bb-4cc7-b17c-36deba2a4cbe"
   },
   "outputs": [],
   "source": [
    "# Split data into past and future observations and reshape\n",
    "\n",
    "train = train_df\n",
    "test = test_df\n",
    "\n",
    "X_train, y_train = split_series(train, n_past, n_future)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))\n",
    "\n",
    "X_test, y_test = split_series(test, n_past, n_future)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n",
    "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))\n",
    "\n",
    "X_val, y_val = split_series(val_df, n_past, n_future)\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], n_features))\n",
    "y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], n_features))\n",
    "\n",
    "print(\"Input Shape: \", X_train.shape, X_test.shape, X_val.shape)\n",
    "print(\"Output Shape: \", y_train.shape, y_test.shape, y_val.shape)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDvUV4OzlUQg"
   },
   "source": [
    "### Create the CNN LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AfP4H5eIiaM",
    "outputId": "399ed683-9e07-4cd6-bb46-521bd7e09fcd"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(window,n_features)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(RepeatVector(y_test.shape[1]))\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(20, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(n_features)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fOZ6n0Ee6-gs",
    "outputId": "b6d5e795-b97f-46bf-f5ef-ba17c2339dbd"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyU10piTlnPn"
   },
   "source": [
    "### Start the Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ogk8XLssLqvR"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "method: training\n",
    "input_parameters: model, X_train, y_train,X_test, y_test\n",
    "output_parameters: none\n",
    "description: This method trains the neural network based on the model passed and also\n",
    "             plots the training results.\n",
    "'''\n",
    "\n",
    "def training(model,X_train, y_train,X_val, y_val):\n",
    "\n",
    "    initial_learning_rate = 0.001\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    # compile the model\n",
    "    model.compile(optimizer=opt, loss='mse', metrics = ['mae']) \n",
    "    history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), batch_size=16, verbose=1)\n",
    "\n",
    "    # plot training performance over the epochs\n",
    "    plot_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CZC26exkLvWR",
    "outputId": "132898d3-56e4-4341-ef16-9898d7e97807"
   },
   "outputs": [],
   "source": [
    "training(model, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RPK1efj1CxC"
   },
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "model.save(\"final_model_hour.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnK5PZ9Klsk6"
   },
   "source": [
    "### Model Evaluation/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brFTIQIY6ftl",
    "outputId": "16317b3e-5d9b-4ea4-e0e9-9eb92ecc7ed7"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('final_model_hour.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQFKpKMD61aB",
    "outputId": "623feb6c-a1a9-4276-d2f3-5184c2a5679e"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1uPIub2ehUJG"
   },
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, y_test, batch_size=8)\n",
    "print(\"Losses are:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVxXBHWFZpaL"
   },
   "source": [
    "### Evaluate and Plot some Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TrdmauHP64Nc",
    "outputId": "b14c6b05-80f6-462e-c623-c7cd3eb739c2"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.reshape(y_pred.shape[0], n_features)\n",
    "y_test = y_test.reshape(y_test.shape[0], n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mig2BSudY49H"
   },
   "outputs": [],
   "source": [
    "# my_scaler = joblib.load(\"scaler.gz\")\n",
    "y_test_unscaled= scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled= scaler.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eshAoZ-UXY5r"
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(y_test_unscaled)\n",
    "df_pred = pd.DataFrame(y_pred_unscaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "bfTJ3vIvaWKj",
    "outputId": "0b9bf18c-aa83-4b7e-9e6e-b4ddb56bae2c"
   },
   "outputs": [],
   "source": [
    "plt.plot(df_test[1])\n",
    "plt.plot(df_pred[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Training_Notebook_Hour.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
